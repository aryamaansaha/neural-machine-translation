{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder Architecture with Attention - French to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXp7gF05YtR7",
    "outputId": "37c1c7fc-b727-4fc1-9608-8d0643bc62a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "True\n",
      "Using Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print('Using', torch.cuda.get_device_name()) if torch.cuda.is_available() else print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tube0LWxAmhx",
    "outputId": "0fadcfc6-db7f-4483-c549-ae8514c7dc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_Zxpq8OqAmkK",
    "outputId": "59b7ea45-a782-4246-873c-44e23b06bf72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-96c6d4ad-4bf1-4bda-b35f-5d098414e7a8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deux jeunes hommes blancs sont dehors près de ...</td>\n",
       "      <td>Two young, White males are outside near many b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plusieurs hommes en casque font fonctionner un...</td>\n",
       "      <td>Several men in hard hats are operating a giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Une petite fille grimpe dans une maisonnette e...</td>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un homme dans une chemise bleue se tient sur u...</td>\n",
       "      <td>A man in a blue shirt is standing on a ladder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deux hommes aux fourneaux préparent à manger.</td>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96c6d4ad-4bf1-4bda-b35f-5d098414e7a8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-96c6d4ad-4bf1-4bda-b35f-5d098414e7a8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-96c6d4ad-4bf1-4bda-b35f-5d098414e7a8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b639d924-962c-4236-a155-81c48c8b9ec3\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b639d924-962c-4236-a155-81c48c8b9ec3')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b639d924-962c-4236-a155-81c48c8b9ec3 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                 SRC  \\\n",
       "0  Deux jeunes hommes blancs sont dehors près de ...   \n",
       "1  Plusieurs hommes en casque font fonctionner un...   \n",
       "2  Une petite fille grimpe dans une maisonnette e...   \n",
       "3  Un homme dans une chemise bleue se tient sur u...   \n",
       "4      Deux hommes aux fourneaux préparent à manger.   \n",
       "\n",
       "                                                 TGT  \n",
       "0  Two young, White males are outside near many b...  \n",
       "1  Several men in hard hats are operating a giant...  \n",
       "2    A little girl climbing into a wooden playhouse.  \n",
       "3  A man in a blue shirt is standing on a ladder ...  \n",
       "4           Two men are at the stove preparing food.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'drive/MyDrive/Neural Machine Translation/Multi30K/'\n",
    "\n",
    "def read_sentences_from_file(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            sentence = line.strip()\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "df_train = pd.DataFrame({'SRC':read_sentences_from_file(path+'train.fr'),\n",
    "                   'TGT':read_sentences_from_file(path+'train.en')})\n",
    "\n",
    "df_test = pd.DataFrame({'SRC':read_sentences_from_file(path+'test_2017_flickr.fr'),\n",
    "                   'TGT':read_sentences_from_file(path+'test_2017_flickr.en')})\n",
    "\n",
    "df_val = pd.DataFrame({'SRC':read_sentences_from_file(path+'val.fr'),\n",
    "                   'TGT':read_sentences_from_file(path+'val.en')})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dK3fMja7AmmO"
   },
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.src = list(df['SRC'])\n",
    "        self.tgt = list(df['TGT'])\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.array(idx)\n",
    "        src_text = np.array(self.src)[idx]\n",
    "        tgt_text = np.array(self.tgt)[idx]\n",
    "        return src_text, tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIttyMSHAmoQ",
    "outputId": "ee7858bc-7d1b-42df-8963-a6ec68dbd024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 29000 Test size: 1000 Val size: 1014\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NMTDataset(df_train)\n",
    "test_dataset = NMTDataset(df_test)\n",
    "val_dataset = NMTDataset(df_val)\n",
    "print(f'Train size: {len(train_dataset)} Test size: {len(test_dataset)} Val size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbCJCTDdA6tl",
    "outputId": "870bead1-f44c-41d9-8b4c-93554d1d90be"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# # !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vSc3amuNA-ru"
   },
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, dataset, lang='en', max_size=float('inf'), min_freq=2):\n",
    "        self.dataset = dataset # expects a list\n",
    "        self.max_size = max_size\n",
    "        if lang=='en':\n",
    "            self.spacy_lang = spacy.load('en_core_web_sm')\n",
    "        elif lang=='de':\n",
    "            self.spacy_lang = spacy.load('de_core_news_sm')\n",
    "        elif lang=='fr':\n",
    "            self.spacy_lang = spacy.load('fr_core_news_sm')\n",
    "        else:\n",
    "            raise Exception('Language not supported')\n",
    "        self.min_freq = min_freq\n",
    "        self.itos = {0:'<START>', 1:'<END>', 2:'<PAD>', 3:'<UNK>'}\n",
    "        self.stoi = {v:k for k, v in self.itos.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [token.text.lower() for token in self.spacy_lang.tokenizer(str(text))]\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        idxs = []\n",
    "        for token in tokens:\n",
    "            if self.stoi.get(token):\n",
    "                idxs.append(self.stoi[token])\n",
    "            else:\n",
    "                idxs.append(self.stoi['<UNK>'])\n",
    "        return idxs\n",
    "\n",
    "    def idx_to_token(self, numericalized):\n",
    "        return [self.itos[num] for num in numericalized]\n",
    "\n",
    "    def build_vocab(self):\n",
    "        freqs = Counter()\n",
    "        idx = len(self.itos)\n",
    "        for i in range(len(self.dataset)):\n",
    "            sentence = self.dataset[i]\n",
    "            for w in self.tokenize(sentence):\n",
    "                freqs[w] += 1\n",
    "        for w, _ in freqs.most_common():\n",
    "            if freqs[w] >= self.min_freq:\n",
    "                self.itos[idx] = w\n",
    "                self.stoi[w] = idx\n",
    "                idx += 1\n",
    "\n",
    "                if idx == self.max_size:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0jjzXJCBT3J",
    "outputId": "56c9cc83-6555-460d-a3b5-a8f1434a6095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size: 6470\n",
      "Target vocab size: 5893\n"
     ]
    }
   ],
   "source": [
    "src_vocab = Vocab(train_dataset.src, lang='fr', max_size=20000, min_freq=2)\n",
    "tgt_vocab = Vocab(train_dataset.tgt, lang='en', max_size=20000, min_freq=2)\n",
    "\n",
    "src_vocab.build_vocab()\n",
    "tgt_vocab.build_vocab()\n",
    "\n",
    "print('Source vocab size:', len(src_vocab))\n",
    "print('Target vocab size:', len(tgt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BouTTg9YBUMR"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def numericalize_and_pad_text(batch, padding_idx, src_vocab, tgt_vocab, batch_first=False, max_seq_len=512):\n",
    "    batch_src, batch_tgt = [], []\n",
    "    for tupl in batch:\n",
    "        src_text, tgt_text = tupl\n",
    "        numericalized_src = [src_vocab.stoi['<START>']] + src_vocab.numericalize(src_text)[:max_seq_len] \\\n",
    "                            + [src_vocab.stoi['<END>']] # truncate at max_seq_len\n",
    "        numericalized_tgt = [tgt_vocab.stoi['<START>']] + tgt_vocab.numericalize(tgt_text)[:max_seq_len] + [tgt_vocab.stoi['<END>']]\n",
    "        batch_src.append(torch.tensor(numericalized_src)) # pad_sequence expects a list of tensors\n",
    "        batch_tgt.append(torch.tensor(numericalized_tgt))\n",
    "    batch_src = pad_sequence(batch_src, batch_first=batch_first, padding_value=padding_idx)\n",
    "    batch_tgt = pad_sequence(batch_tgt, batch_first=batch_first, padding_value=padding_idx)\n",
    "\n",
    "    return batch_src.to(device), batch_tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cbRkGGwuB0YJ"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "batch_size = 128\n",
    "max_seq_len = 512\n",
    "collate_fn = partial(numericalize_and_pad_text,\n",
    "                     src_vocab=src_vocab,\n",
    "                     tgt_vocab=tgt_vocab,\n",
    "                     padding_idx=tgt_vocab.stoi[\"<PAD>\"],\n",
    "                     max_seq_len = max_seq_len,\n",
    "                     batch_first=False)\n",
    "\n",
    "trainloader = DataLoader(dataset=train_dataset, shuffle=True,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)\n",
    "testloader = DataLoader(dataset=test_dataset, shuffle=False,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)\n",
    "valloader = DataLoader(dataset=val_dataset, shuffle=False,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVZPVTV9B3AK",
    "outputId": "e0fa9f43-bddd-4313-8399-13d10f7d26d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 128]) torch.Size([31, 128])\n",
      "torch.Size([26, 128]) torch.Size([28, 128])\n",
      "torch.Size([26, 128]) torch.Size([29, 128])\n",
      "torch.Size([33, 128]) torch.Size([32, 128])\n",
      "torch.Size([27, 128]) torch.Size([25, 128])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(trainloader):\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TJJstPzvB-B9"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, len_vocab_src, emb_dim, enc_hidden_dim, dec_hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.len_vocab_src = len_vocab_src\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len_vocab_src, embedding_dim=emb_dim)\n",
    "        self.gru_layers = nn.GRU(emb_dim, enc_hidden_dim, num_layers=1, batch_first=False, bidirectional=True) # can't apply dropout on last layer\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim, dec_hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_embedding = nn.Dropout(0.5)(self.embeddings(src)) # (seq_len, batch_size) ->  (seq_len, batch_size, emb_dim)\n",
    "\n",
    "        # top_layer_hidden_states = (seq_len, batch_size, 2*enc_hidden_dim)\n",
    "        top_layer_hidden_states, hT = self.gru_layers(src_embedding) # hT = (2*num_layers, batch_size, enc_hidden_dim) [no. of directions=2]\n",
    "        hT_for, hT_back = hT[-2, :, :], hT[-1, :, :]\n",
    "        hT = torch.tanh(self.fc(torch.cat((hT_for, hT_back), dim=1))) # hT = (batch size, dec_hidden_dim)\n",
    "        return top_layer_hidden_states, hT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sYrz8QL7BBKz"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.alignment = nn.Linear(2*enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.score = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, top_layer_hidden_states, hT):\n",
    "        src_seq_len, batch_size, _ = top_layer_hidden_states.shape\n",
    "        hT = hT.unsqueeze(1).repeat(1, src_seq_len, 1) # hT = (batch size, src_seq_len, dec_hidden_dim)\n",
    "        top_layer_hidden_states = top_layer_hidden_states.permute(1, 0, 2) # top_layer_hidden_states = (batch_size, src_seq_len, 2*enc_hidden_dim)\n",
    "        aligned = torch.tanh(self.alignment(torch.cat((hT, top_layer_hidden_states), dim = 2))) # aligned = (batch_size, src_seq_len, dec_hidden_dim)\n",
    "        attention = self.score(aligned).squeeze(2)  # attention = (batch_size, src_seq_len)\n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xJ6xdE5sC6uj"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, len_vocab_tgt, emb_dim, enc_hidden_dim, dec_hidden_dim, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.len_vocab_tgt = len_vocab_tgt\n",
    "        self.attention = attention\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len_vocab_tgt, embedding_dim=emb_dim)\n",
    "        self.gru_layers = nn.GRU(2*enc_hidden_dim + emb_dim, dec_hidden_dim, batch_first=False) # hidden_dim and num_layers should match that of encoder\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim + dec_hidden_dim + emb_dim, len_vocab_tgt)\n",
    "\n",
    "    def forward(self, tgt, ht, top_layer_hidden_states):\n",
    "        tgt = tgt.unsqueeze(0) # (seq_len=1, batch_size)\n",
    "        tgt_embedding = nn.Dropout(0.5)(self.embeddings(tgt)) # (seq_len=1, batch_size) ->  (seq_len=1, batch_size, emb_dim)\n",
    "        a =  self.attention(top_layer_hidden_states, ht) # a = (batch_size, src_seq_len)\n",
    "        a = a.unsqueeze(1) # a = (batch_size, 1, src_seq_len)\n",
    "        top_layer_hidden_states = top_layer_hidden_states.permute(1, 0, 2) # top_layer_hidden_states = (batch_size, src_seq_len, 2*enc_hidden_dim)\n",
    "        weighted_hidden_states = torch.bmm(a, top_layer_hidden_states) # weighted_hidden_states = (batch_size, 1, 2*enc_hidden_dim)\n",
    "        weighted_hidden_states = weighted_hidden_states.permute(1, 0, 2) # weighted_hidden_states = (1, batch_size, 2*enc_hidden_dim)\n",
    "        inp = torch.cat((tgt_embedding, weighted_hidden_states), dim=2) # inp = (seq_len=1, batch_size, 2*enc_hidden_dim+emb_dim)\n",
    "        # top_layer_hidden_states = (seq_len=1, batch_size, dec_hidden_dim*1) [no. of directions=1]\n",
    "        top_layer_hidden_states, ht = self.gru_layers(inp, ht.unsqueeze(0)) # ht = (1*1, batch_size, dec_hidden_dim) [no. of directions=1, num_layers=1]\n",
    "        ht = ht.squeeze(0) # ht = (batch_size, dec_hidden_dim)\n",
    "        fc_input = torch.cat((top_layer_hidden_states.squeeze(0), weighted_hidden_states.squeeze(0), tgt_embedding.squeeze(0)), dim=1)\n",
    "        out = self.fc(fc_input)\n",
    "        return out, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FwoRYitCUBE1"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt, tfratio):\n",
    "        len_vocab_tgt = self.decoder.len_vocab_tgt\n",
    "        tgt_seq_len, batch_size = tgt.shape # tgt = (tgt_seq_len, batch_size)\n",
    "        decoder_outputs = torch.zeros(tgt_seq_len, batch_size, len_vocab_tgt).to(device)\n",
    "        top_layer_hidden_states, ht = self.encoder(src)\n",
    "\n",
    "        dec_input = tgt[0, :] # <START> token\n",
    "\n",
    "        # Sequentially generating decoder output\n",
    "        for i in range(1, tgt_seq_len):\n",
    "            out, ht = self.decoder(dec_input, ht, top_layer_hidden_states) # out = top layer hidden states of decoder\n",
    "            decoder_outputs[i] = out\n",
    "            teacher_force = np.random.random() < tfratio # True if we do teacher forcing\n",
    "            pred_token = out.argmax(dim=1)\n",
    "            dec_input = tgt[i] if teacher_force else pred_token\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HZykqLd2Jzwk"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len_vocab_src=len(src_vocab), emb_dim=256, enc_hidden_dim=512, dec_hidden_dim=512)\n",
    "attention = Attention(enc_hidden_dim=512, dec_hidden_dim=512)\n",
    "decoder = Decoder(len_vocab_tgt=len(tgt_vocab), emb_dim=256, enc_hidden_dim=512, dec_hidden_dim=512, attention=attention)\n",
    "\n",
    "model = Model(encoder, decoder).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = tgt_vocab.stoi['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFbhes0IJ-Sz",
    "outputId": "ba3399c3-f721-4546-a745-2f0d1b8dc905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): Embedding(6470, 256)\n",
       "    (gru_layers): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (alignment): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (score): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embeddings): Embedding(5893, 256)\n",
       "    (gru_layers): GRU(1280, 512)\n",
       "    (fc): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_initialization(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(weight_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg48bSYeKzIP",
    "outputId": "fab137ac-5a5c-4556-aa0d-5cdec595a011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 20164357\n"
     ]
    }
   ],
   "source": [
    "print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wz1JKlpWKSnE"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for batch in trainloader:\n",
    "        src, tgt = batch\n",
    "        optimizer.zero_grad()\n",
    "        dec_out = model(src, tgt, tfratio=0.5)\n",
    "        dec_out = dec_out[1:].view(-1, model.decoder.len_vocab_tgt) # first index of decoder_outputs is just zeros/isn't being used\n",
    "        tgt = tgt[1:].view(-1) # first index of tgt is just start token\n",
    "        loss = loss_fn(dec_out, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1) # gradient clipping\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return sum(losses) / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "H6IWmHW1KSo6"
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            src, tgt = batch\n",
    "            dec_out = model(src, tgt, tfratio=0) # no teacher forcing in testing\n",
    "            dec_out = dec_out[1:].view(-1, model.decoder.len_vocab_tgt) # first index of decoder_outputs is just zeros/isn't being used\n",
    "            tgt = tgt[1:].view(-1) # first index of tgt is just start token\n",
    "            loss = loss_fn(dec_out, tgt)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return sum(losses) / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "s4mQbCkyKSrv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_epoch(start, end):\n",
    "    diff = end - start\n",
    "    mins = int(diff / 60)\n",
    "    secs = int(diff - (mins * 60))\n",
    "    return mins, secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "zyTEtZIHLeRl",
    "outputId": "3cd8172f-5a1c-49ee-a96f-951040e5c0e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fb53b946-6aca-43de-9fcb-6a226314d9d3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Perplexity</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Perplexity</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.050</td>\n",
       "      <td>156.07</td>\n",
       "      <td>4.765</td>\n",
       "      <td>117.31</td>\n",
       "      <td>10min 14s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.159</td>\n",
       "      <td>64.01</td>\n",
       "      <td>4.327</td>\n",
       "      <td>75.69</td>\n",
       "      <td>10min 12s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.380</td>\n",
       "      <td>29.36</td>\n",
       "      <td>3.648</td>\n",
       "      <td>38.41</td>\n",
       "      <td>10min 14s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.608</td>\n",
       "      <td>13.58</td>\n",
       "      <td>3.202</td>\n",
       "      <td>24.58</td>\n",
       "      <td>10min 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.129</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.108</td>\n",
       "      <td>22.37</td>\n",
       "      <td>11min 19s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.781</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3.055</td>\n",
       "      <td>21.22</td>\n",
       "      <td>10min 16s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb53b946-6aca-43de-9fcb-6a226314d9d3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fb53b946-6aca-43de-9fcb-6a226314d9d3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fb53b946-6aca-43de-9fcb-6a226314d9d3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-4a9aabaa-55d6-4e30-a7c4-ef9ee910c5c1\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a9aabaa-55d6-4e30-a7c4-ef9ee910c5c1')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-4a9aabaa-55d6-4e30-a7c4-ef9ee910c5c1 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Epoch Train Loss Train Perplexity Val Loss Val Perplexity       Time\n",
       "0      1      5.050           156.07    4.765         117.31  10min 14s\n",
       "1      2      4.159            64.01    4.327          75.69  10min 12s\n",
       "2      3      3.380            29.36    3.648          38.41  10min 14s\n",
       "3      4      2.608            13.58    3.202          24.58  10min 22s\n",
       "4      5      2.129             8.40    3.108          22.37  11min 19s\n",
       "5      6      1.781             5.94    3.055          21.22  10min 16s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import math\n",
    "res = pd.DataFrame(columns=['Epoch', 'Train Loss', 'Train Perplexity', 'Val Loss', 'Val Perplexity', 'Time'])\n",
    "display.display(res)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(6):\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss = train()\n",
    "    val_loss = evaluate(valloader)\n",
    "    end = time.time()\n",
    "    mins, secs = time_epoch(start, end)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './drive/MyDrive/Neural Machine Translation/EncDecAttn_fr2en.pth')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    res.loc[len(res)] = [epoch+1, f'{train_loss:.3f}', f'{math.exp(train_loss):.2f}', f'{val_loss:.3f}', f'{math.exp(val_loss):.2f}', f'{mins}min {secs}s']\n",
    "    display.display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd32WSB8Le38",
    "outputId": "81c71b21-8f9e-4ddb-cec3-e8a4d76c89dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./drive/MyDrive/Neural Machine Translation/EncDecAttn_fr2en.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT3rqTtbLe5r",
    "outputId": "afe58d79-6a7d-4851-9801-8aa68d007b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.3506730794906616 | Test Perplexity: 28.521924707041716\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "test_loss = evaluate(testloader)\n",
    "print(f'Test Loss: {test_loss} | Test Perplexity: {math.exp(test_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaA04pMXp_Qy",
    "outputId": "d06e3257-5551-44c0-a228-2eb10f4cdc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total BLEU Score: 14.64\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "def reverse_numericalize(tensor, vocab):\n",
    "    lst = tensor.detach().tolist()\n",
    "    lst =  [num for num in lst if num not in [0, 1, 2, 3]]\n",
    "    return vocab.idx_to_token(lst)\n",
    "\n",
    "def total_bleu_score(model, testloader, src_vocab, tgt_vocab):\n",
    "    model.eval()\n",
    "    all_references = []\n",
    "    all_candidates = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            src, tgt = batch\n",
    "            dec_out = model(src, tgt, tfratio=0)\n",
    "            tgt_pred = dec_out.argmax(dim=2)\n",
    "\n",
    "            tgt_sentences = [reverse_numericalize(tgt[:, i], tgt_vocab) for i in range(tgt.size(1))]\n",
    "            # Reverse numericalize translated tensors\n",
    "            translated_sentences = [reverse_numericalize(tgt_pred[:, i], tgt_vocab) for i in range(tgt_pred.size(1))]\n",
    "\n",
    "            all_references.extend(tgt_sentences)\n",
    "            all_candidates.extend(translated_sentences)\n",
    "\n",
    "    score = bleu_score(all_candidates, all_references, max_n=1, weights=[1])\n",
    "    return score\n",
    "\n",
    "score = total_bleu_score(model, testloader, src_vocab, tgt_vocab)\n",
    "print(f'Total BLEU Score: {score * 100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
