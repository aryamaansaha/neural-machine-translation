{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder Architecture with Attention - German to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXp7gF05YtR7",
    "outputId": "6aad8d7d-bb69-4e86-e3fe-8840ac26a2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "True\n",
      "Using Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print('Using', torch.cuda.get_device_name()) if torch.cuda.is_available() else print('Using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tube0LWxAmhx",
    "outputId": "8f41d331-ed6f-4644-e50d-e65f09dc7c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_Zxpq8OqAmkK",
    "outputId": "44b82dc6-4de8-42fc-bd1e-a7c31b568589"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e941510e-ca11-4498-985c-01a624ff0bc3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC</th>\n",
       "      <th>TGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
       "      <td>Two young, White males are outside near many b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
       "      <td>Several men in hard hats are operating a giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ein Mann in einem blauen Hemd steht auf einer ...</td>\n",
       "      <td>A man in a blue shirt is standing on a ladder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e941510e-ca11-4498-985c-01a624ff0bc3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e941510e-ca11-4498-985c-01a624ff0bc3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e941510e-ca11-4498-985c-01a624ff0bc3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b460911a-9b0b-431d-8d06-829c8d499d71\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b460911a-9b0b-431d-8d06-829c8d499d71')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b460911a-9b0b-431d-8d06-829c8d499d71 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                 SRC  \\\n",
       "0  Zwei junge weiße Männer sind im Freien in der ...   \n",
       "1  Mehrere Männer mit Schutzhelmen bedienen ein A...   \n",
       "2  Ein kleines Mädchen klettert in ein Spielhaus ...   \n",
       "3  Ein Mann in einem blauen Hemd steht auf einer ...   \n",
       "4  Zwei Männer stehen am Herd und bereiten Essen zu.   \n",
       "\n",
       "                                                 TGT  \n",
       "0  Two young, White males are outside near many b...  \n",
       "1  Several men in hard hats are operating a giant...  \n",
       "2    A little girl climbing into a wooden playhouse.  \n",
       "3  A man in a blue shirt is standing on a ladder ...  \n",
       "4           Two men are at the stove preparing food.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'drive/MyDrive/Neural Machine Translation/Multi30K/'\n",
    "\n",
    "def read_sentences_from_file(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            sentence = line.strip()\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "df_train = pd.DataFrame({'SRC':read_sentences_from_file(path+'train.de'),\n",
    "                   'TGT':read_sentences_from_file(path+'train.en')})\n",
    "\n",
    "df_test = pd.DataFrame({'SRC':read_sentences_from_file(path+'test_2017_flickr.de'),\n",
    "                   'TGT':read_sentences_from_file(path+'test_2017_flickr.en')})\n",
    "\n",
    "df_val = pd.DataFrame({'SRC':read_sentences_from_file(path+'val.de'),\n",
    "                   'TGT':read_sentences_from_file(path+'val.en')})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dK3fMja7AmmO"
   },
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.src = list(df['SRC'])\n",
    "        self.tgt = list(df['TGT'])\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.array(idx)\n",
    "        src_text = np.array(self.src)[idx]\n",
    "        tgt_text = np.array(self.tgt)[idx]\n",
    "        return src_text, tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIttyMSHAmoQ",
    "outputId": "98889a29-3bb4-4d9f-caf5-468de30b142e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 29000 Test size: 1000 Val size: 1014\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NMTDataset(df_train)\n",
    "test_dataset = NMTDataset(df_test)\n",
    "val_dataset = NMTDataset(df_val)\n",
    "print(f'Train size: {len(train_dataset)} Test size: {len(test_dataset)} Val size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbCJCTDdA6tl",
    "outputId": "b7be3e6d-c50c-4457-da7b-3d0e3e4f6d75"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# # !python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vSc3amuNA-ru"
   },
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, dataset, lang='en', max_size=float('inf'), min_freq=2):\n",
    "        self.dataset = dataset # expects a list\n",
    "        self.max_size = max_size\n",
    "        if lang=='en':\n",
    "            self.spacy_lang = spacy.load('en_core_web_sm')\n",
    "        elif lang=='de':\n",
    "            self.spacy_lang = spacy.load('de_core_news_sm')\n",
    "        elif lang=='fr':\n",
    "            self.spacy_lang = spacy.load('fr_core_news_sm')\n",
    "        else:\n",
    "            raise Exception('Language not supported')\n",
    "        self.min_freq = min_freq\n",
    "        self.itos = {0:'<START>', 1:'<END>', 2:'<PAD>', 3:'<UNK>'}\n",
    "        self.stoi = {v:k for k, v in self.itos.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [token.text.lower() for token in self.spacy_lang.tokenizer(str(text))]\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        idxs = []\n",
    "        for token in tokens:\n",
    "            if self.stoi.get(token):\n",
    "                idxs.append(self.stoi[token])\n",
    "            else:\n",
    "                idxs.append(self.stoi['<UNK>'])\n",
    "        return idxs\n",
    "\n",
    "    def idx_to_token(self, numericalized):\n",
    "        return [self.itos[num] for num in numericalized]\n",
    "\n",
    "    def build_vocab(self):\n",
    "        freqs = Counter()\n",
    "        idx = len(self.itos)\n",
    "        for i in range(len(self.dataset)):\n",
    "            sentence = self.dataset[i]\n",
    "            for w in self.tokenize(sentence):\n",
    "                freqs[w] += 1\n",
    "        for w, _ in freqs.most_common():\n",
    "            if freqs[w] >= self.min_freq:\n",
    "                self.itos[idx] = w\n",
    "                self.stoi[w] = idx\n",
    "                idx += 1\n",
    "\n",
    "                if idx == self.max_size:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0jjzXJCBT3J",
    "outputId": "6e107117-f6f7-4860-ebda-4181b15b1f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size: 7853\n",
      "Target vocab size: 5893\n"
     ]
    }
   ],
   "source": [
    "src_vocab = Vocab(train_dataset.src, lang='de', max_size=20000, min_freq=2)\n",
    "tgt_vocab = Vocab(train_dataset.tgt, lang='en', max_size=20000, min_freq=2)\n",
    "\n",
    "src_vocab.build_vocab()\n",
    "tgt_vocab.build_vocab()\n",
    "\n",
    "print('Source vocab size:', len(src_vocab))\n",
    "print('Target vocab size:', len(tgt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BouTTg9YBUMR"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def numericalize_and_pad_text(batch, padding_idx, src_vocab, tgt_vocab, batch_first=False, max_seq_len=512):\n",
    "    batch_src, batch_tgt = [], []\n",
    "    for tupl in batch:\n",
    "        src_text, tgt_text = tupl\n",
    "        numericalized_src = [src_vocab.stoi['<START>']] + src_vocab.numericalize(src_text)[:max_seq_len] \\\n",
    "                            + [src_vocab.stoi['<END>']] # truncate at max_seq_len\n",
    "        numericalized_tgt = [tgt_vocab.stoi['<START>']] + tgt_vocab.numericalize(tgt_text)[:max_seq_len] + [tgt_vocab.stoi['<END>']]\n",
    "        batch_src.append(torch.tensor(numericalized_src)) # pad_sequence expects a list of tensors\n",
    "        batch_tgt.append(torch.tensor(numericalized_tgt))\n",
    "    batch_src = pad_sequence(batch_src, batch_first=batch_first, padding_value=padding_idx)\n",
    "    batch_tgt = pad_sequence(batch_tgt, batch_first=batch_first, padding_value=padding_idx)\n",
    "\n",
    "    return batch_src.to(device), batch_tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cbRkGGwuB0YJ"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "batch_size = 128\n",
    "max_seq_len = 512\n",
    "collate_fn = partial(numericalize_and_pad_text,\n",
    "                     src_vocab=src_vocab,\n",
    "                     tgt_vocab=tgt_vocab,\n",
    "                     padding_idx=tgt_vocab.stoi[\"<PAD>\"],\n",
    "                     max_seq_len = max_seq_len,\n",
    "                     batch_first=False)\n",
    "\n",
    "trainloader = DataLoader(dataset=train_dataset, shuffle=True,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)\n",
    "testloader = DataLoader(dataset=test_dataset, shuffle=False,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)\n",
    "valloader = DataLoader(dataset=val_dataset, shuffle=False,\n",
    "                        batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVZPVTV9B3AK",
    "outputId": "e0fa9f43-bddd-4313-8399-13d10f7d26d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 128]) torch.Size([31, 128])\n",
      "torch.Size([26, 128]) torch.Size([28, 128])\n",
      "torch.Size([26, 128]) torch.Size([29, 128])\n",
      "torch.Size([33, 128]) torch.Size([32, 128])\n",
      "torch.Size([27, 128]) torch.Size([25, 128])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(trainloader):\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "TJJstPzvB-B9"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, len_vocab_src, emb_dim, enc_hidden_dim, dec_hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.len_vocab_src = len_vocab_src\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len_vocab_src, embedding_dim=emb_dim)\n",
    "        self.gru_layers = nn.GRU(emb_dim, enc_hidden_dim, num_layers=1, batch_first=False, bidirectional=True) # can't apply dropout on last layer\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim, dec_hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_embedding = nn.Dropout(0.5)(self.embeddings(src)) # (seq_len, batch_size) ->  (seq_len, batch_size, emb_dim)\n",
    "\n",
    "        # top_layer_hidden_states = (seq_len, batch_size, 2*enc_hidden_dim)\n",
    "        top_layer_hidden_states, hT = self.gru_layers(src_embedding) # hT = (2*num_layers, batch_size, enc_hidden_dim) [no. of directions=2]\n",
    "        hT_for, hT_back = hT[-2, :, :], hT[-1, :, :]\n",
    "        hT = torch.tanh(self.fc(torch.cat((hT_for, hT_back), dim=1))) # hT = (batch size, dec_hidden_dim)\n",
    "        return top_layer_hidden_states, hT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "sYrz8QL7BBKz"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.alignment = nn.Linear(2*enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.score = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, top_layer_hidden_states, hT):\n",
    "        src_seq_len, batch_size, _ = top_layer_hidden_states.shape\n",
    "        hT = hT.unsqueeze(1).repeat(1, src_seq_len, 1) # hT = (batch size, src_seq_len, dec_hidden_dim)\n",
    "        top_layer_hidden_states = top_layer_hidden_states.permute(1, 0, 2) # top_layer_hidden_states = (batch_size, src_seq_len, 2*enc_hidden_dim)\n",
    "        aligned = torch.tanh(self.alignment(torch.cat((hT, top_layer_hidden_states), dim = 2))) # aligned = (batch_size, src_seq_len, dec_hidden_dim)\n",
    "        attention = self.score(aligned).squeeze(2)  # attention = (batch_size, src_seq_len)\n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "xJ6xdE5sC6uj"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, len_vocab_tgt, emb_dim, enc_hidden_dim, dec_hidden_dim, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.len_vocab_tgt = len_vocab_tgt\n",
    "        self.attention = attention\n",
    "        self.embeddings = nn.Embedding(num_embeddings=len_vocab_tgt, embedding_dim=emb_dim)\n",
    "        self.gru_layers = nn.GRU(2*enc_hidden_dim + emb_dim, dec_hidden_dim, batch_first=False) # hidden_dim and num_layers should match that of encoder\n",
    "        self.fc = nn.Linear(2*enc_hidden_dim + dec_hidden_dim + emb_dim, len_vocab_tgt)\n",
    "\n",
    "    def forward(self, tgt, ht, top_layer_hidden_states):\n",
    "        tgt = tgt.unsqueeze(0) # (seq_len=1, batch_size)\n",
    "        tgt_embedding = nn.Dropout(0.5)(self.embeddings(tgt)) # (seq_len=1, batch_size) ->  (seq_len=1, batch_size, emb_dim)\n",
    "        a =  self.attention(top_layer_hidden_states, ht) # a = (batch_size, src_seq_len)\n",
    "        a = a.unsqueeze(1) # a = (batch_size, 1, src_seq_len)\n",
    "        top_layer_hidden_states = top_layer_hidden_states.permute(1, 0, 2) # top_layer_hidden_states = (batch_size, src_seq_len, 2*enc_hidden_dim)\n",
    "        weighted_hidden_states = torch.bmm(a, top_layer_hidden_states) # weighted_hidden_states = (batch_size, 1, 2*enc_hidden_dim)\n",
    "        weighted_hidden_states = weighted_hidden_states.permute(1, 0, 2) # weighted_hidden_states = (1, batch_size, 2*enc_hidden_dim)\n",
    "        inp = torch.cat((tgt_embedding, weighted_hidden_states), dim=2) # inp = (seq_len=1, batch_size, 2*enc_hidden_dim+emb_dim)\n",
    "        # top_layer_hidden_states = (seq_len=1, batch_size, dec_hidden_dim*1) [no. of directions=1]\n",
    "        top_layer_hidden_states, ht = self.gru_layers(inp, ht.unsqueeze(0)) # ht = (1*1, batch_size, dec_hidden_dim) [no. of directions=1, num_layers=1]\n",
    "        ht = ht.squeeze(0) # ht = (batch_size, dec_hidden_dim)\n",
    "        fc_input = torch.cat((top_layer_hidden_states.squeeze(0), weighted_hidden_states.squeeze(0), tgt_embedding.squeeze(0)), dim=1)\n",
    "        out = self.fc(fc_input)\n",
    "        return out, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "FwoRYitCUBE1"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt, tfratio):\n",
    "        len_vocab_tgt = self.decoder.len_vocab_tgt\n",
    "        tgt_seq_len, batch_size = tgt.shape # tgt = (tgt_seq_len, batch_size)\n",
    "        decoder_outputs = torch.zeros(tgt_seq_len, batch_size, len_vocab_tgt).to(device)\n",
    "        top_layer_hidden_states, ht = self.encoder(src)\n",
    "\n",
    "        dec_input = tgt[0, :] # <START> token\n",
    "\n",
    "        # Sequentially generating decoder output\n",
    "        for i in range(1, tgt_seq_len):\n",
    "            out, ht = self.decoder(dec_input, ht, top_layer_hidden_states) # out = top layer hidden states of decoder\n",
    "            decoder_outputs[i] = out\n",
    "            teacher_force = np.random.random() < tfratio # True if we do teacher forcing\n",
    "            pred_token = out.argmax(dim=1)\n",
    "            dec_input = tgt[i] if teacher_force else pred_token\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "HZykqLd2Jzwk"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len_vocab_src=len(src_vocab), emb_dim=256, enc_hidden_dim=512, dec_hidden_dim=512)\n",
    "attention = Attention(enc_hidden_dim=512, dec_hidden_dim=512)\n",
    "decoder = Decoder(len_vocab_tgt=len(tgt_vocab), emb_dim=256, enc_hidden_dim=512, dec_hidden_dim=512, attention=attention)\n",
    "\n",
    "model = Model(encoder, decoder).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = tgt_vocab.stoi['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFbhes0IJ-Sz",
    "outputId": "6a132b24-c2ae-4218-9350-7dfdaa3eee93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): Encoder(\n",
       "    (embeddings): Embedding(7853, 256)\n",
       "    (gru_layers): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (alignment): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (score): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embeddings): Embedding(5893, 256)\n",
       "    (gru_layers): GRU(1280, 512)\n",
       "    (fc): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_initialization(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(weight_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg48bSYeKzIP",
    "outputId": "87051111-1446-46e7-a5b5-080e00487050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 20518405\n"
     ]
    }
   ],
   "source": [
    "print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "wz1JKlpWKSnE"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for batch in trainloader:\n",
    "        src, tgt = batch\n",
    "        optimizer.zero_grad()\n",
    "        dec_out = model(src, tgt, tfratio=0.5)\n",
    "        dec_out = dec_out[1:].view(-1, model.decoder.len_vocab_tgt) # first index of decoder_outputs is just zeros/isn't being used\n",
    "        tgt = tgt[1:].view(-1) # first index of tgt is just start token\n",
    "        loss = loss_fn(dec_out, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1) # gradient clipping\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return sum(losses) / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "H6IWmHW1KSo6"
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            src, tgt = batch\n",
    "            dec_out = model(src, tgt, tfratio=0) # no teacher forcing in testing\n",
    "            dec_out = dec_out[1:].view(-1, model.decoder.len_vocab_tgt) # first index of decoder_outputs is just zeros/isn't being used\n",
    "            tgt = tgt[1:].view(-1) # first index of tgt is just start token\n",
    "            loss = loss_fn(dec_out, tgt)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return sum(losses) / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "s4mQbCkyKSrv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_epoch(start, end):\n",
    "    diff = end - start\n",
    "    mins = int(diff / 60)\n",
    "    secs = int(diff - (mins * 60))\n",
    "    return mins, secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "zyTEtZIHLeRl",
    "outputId": "ce31c0e1-4e9b-4494-d20e-0345903a9064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cbbb6f64-5665-4af5-95d9-886ed72532a3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Perplexity</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Perplexity</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.077</td>\n",
       "      <td>160.24</td>\n",
       "      <td>4.829</td>\n",
       "      <td>125.09</td>\n",
       "      <td>11min 7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.104</td>\n",
       "      <td>60.56</td>\n",
       "      <td>4.250</td>\n",
       "      <td>70.09</td>\n",
       "      <td>11min 2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.406</td>\n",
       "      <td>30.14</td>\n",
       "      <td>3.770</td>\n",
       "      <td>43.38</td>\n",
       "      <td>11min 52s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.900</td>\n",
       "      <td>18.17</td>\n",
       "      <td>3.470</td>\n",
       "      <td>32.15</td>\n",
       "      <td>11min 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.492</td>\n",
       "      <td>12.08</td>\n",
       "      <td>3.450</td>\n",
       "      <td>31.51</td>\n",
       "      <td>11min 26s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.212</td>\n",
       "      <td>9.13</td>\n",
       "      <td>3.308</td>\n",
       "      <td>27.32</td>\n",
       "      <td>11min 29s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.962</td>\n",
       "      <td>7.11</td>\n",
       "      <td>3.357</td>\n",
       "      <td>28.70</td>\n",
       "      <td>10min 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.741</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.442</td>\n",
       "      <td>31.25</td>\n",
       "      <td>11min 12s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbbb6f64-5665-4af5-95d9-886ed72532a3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cbbb6f64-5665-4af5-95d9-886ed72532a3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cbbb6f64-5665-4af5-95d9-886ed72532a3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-25ba54ba-7ee6-4f52-bbcf-d27bcc031a7b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25ba54ba-7ee6-4f52-bbcf-d27bcc031a7b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-25ba54ba-7ee6-4f52-bbcf-d27bcc031a7b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Epoch Train Loss Train Perplexity Val Loss Val Perplexity       Time\n",
       "0      1      5.077           160.24    4.829         125.09   11min 7s\n",
       "1      2      4.104            60.56    4.250          70.09   11min 2s\n",
       "2      3      3.406            30.14    3.770          43.38  11min 52s\n",
       "3      4      2.900            18.17    3.470          32.15  11min 58s\n",
       "4      5      2.492            12.08    3.450          31.51  11min 26s\n",
       "5      6      2.212             9.13    3.308          27.32  11min 29s\n",
       "6      7      1.962             7.11    3.357          28.70  10min 58s\n",
       "7      8      1.741             5.71    3.442          31.25  11min 12s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-7c469793ca8f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-a8055b408bd9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d85668436fe2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msrc_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msrc_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import math\n",
    "res = pd.DataFrame(columns=['Epoch', 'Train Loss', 'Train Perplexity', 'Val Loss', 'Val Perplexity', 'Time'])\n",
    "display.display(res)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(10):\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss = train()\n",
    "    val_loss = evaluate(valloader)\n",
    "    end = time.time()\n",
    "    mins, secs = time_epoch(start, end)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './drive/MyDrive/Neural Machine Translation/EncDecAttn_de2en.pth')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    res.loc[len(res)] = [epoch+1, f'{train_loss:.3f}', f'{math.exp(train_loss):.2f}', f'{val_loss:.3f}', f'{math.exp(val_loss):.2f}', f'{mins}min {secs}s']\n",
    "    display.display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd32WSB8Le38",
    "outputId": "81c71b21-8f9e-4ddb-cec3-e8a4d76c89dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./drive/MyDrive/Neural Machine Translation/EncDecAttn_de2en.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT3rqTtbLe5r",
    "outputId": "11db4014-da9c-4ab2-d616-8279abb025c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.847332000732422 | Test Perplexity: 46.86785287813471\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "test_loss = evaluate(testloader)\n",
    "print(f'Test Loss: {test_loss} | Test Perplexity: {math.exp(test_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaA04pMXp_Qy",
    "outputId": "ba48d7f4-1ae2-4959-c146-efeb764e8cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total BLEU Score: 14.86\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "def reverse_numericalize(tensor, vocab):\n",
    "    lst = tensor.detach().tolist()\n",
    "    lst =  [num for num in lst if num not in [0, 1, 2, 3]]\n",
    "    return vocab.idx_to_token(lst)\n",
    "\n",
    "def total_bleu_score(model, testloader, src_vocab, tgt_vocab):\n",
    "    model.eval()\n",
    "    all_references = []\n",
    "    all_candidates = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            src, tgt = batch\n",
    "            dec_out = model(src, tgt, tfratio=0)\n",
    "            tgt_pred = dec_out.argmax(dim=2)\n",
    "\n",
    "            tgt_sentences = [reverse_numericalize(tgt[:, i], tgt_vocab) for i in range(tgt.size(1))]\n",
    "            # Reverse numericalize translated tensors\n",
    "            translated_sentences = [reverse_numericalize(tgt_pred[:, i], tgt_vocab) for i in range(tgt_pred.size(1))]\n",
    "\n",
    "            all_references.extend(tgt_sentences)\n",
    "            all_candidates.extend(translated_sentences)\n",
    "\n",
    "    score = bleu_score(all_candidates, all_references, max_n=1, weights=[1])\n",
    "    return score\n",
    "\n",
    "score = total_bleu_score(model, testloader, src_vocab, tgt_vocab)\n",
    "print(f'Total BLEU Score: {score * 100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
